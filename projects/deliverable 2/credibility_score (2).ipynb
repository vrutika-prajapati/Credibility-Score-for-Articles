{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Vrutika Prajapati\n",
        "*   U01994496\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LSKXldBgFY_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "class URLValidator:\n",
        "    \"\"\"\n",
        "    A production-ready URL validation class that evaluates the credibility of a webpage\n",
        "    using multiple factors: domain trust, content relevance, fact-checking, bias detection, and citations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.serpapi_key = '3ca058cff0f926a3db441da5c1aae0868ffc7b98d95c9040e0989a1dfd918390'\n",
        "\n",
        "        # Load models once to avoid redundant API calls\n",
        "        self.similarity_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "        self.fake_news_classifier = pipeline(\"text-classification\", model=\"mrm8488/bert-tiny-finetuned-fake-news-detection\")\n",
        "        self.sentiment_analyzer = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "\n",
        "    def fetch_page_content(self, url: str) -> str:\n",
        "        \"\"\"Fetches and extracts text content from the given URL with error handling.\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            return \" \".join([p.text for p in soup.find_all(\"p\")])\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error fetching {url}: {e}\")\n",
        "            return \"\"\n",
        "    def save_to_csv(self, user_prompt: str, url_to_check: str, func_rating: float, custom_rating: float):\n",
        "        with open('credibility_scores.csv', mode='a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([user_prompt, url_to_check, func_rating, custom_rating])\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        \"\"\"Cleans text by removing stopwords, special characters, and lowercasing.\"\"\"\n",
        "        text = re.sub(r'\\W+', ' ', text.lower())\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        return \" \".join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "    def get_domain_trust(self, content: str) -> int:\n",
        "        \"\"\"Computes the domain trust score based on content credibility.\"\"\"\n",
        "        if not content:\n",
        "            return 50  # Default score\n",
        "        result = self.fake_news_classifier(content[:512])[0]\n",
        "        return 100 if result[\"label\"] == \"REAL\" else 30 if result[\"label\"] == \"FAKE\" else 50\n",
        "\n",
        "    def compute_similarity_score(self, user_query: str, content: str) -> int:\n",
        "        \"\"\"Computes semantic similarity between user query and page content.\"\"\"\n",
        "        if not content:\n",
        "            return 0\n",
        "        query_clean = self.preprocess_text(user_query)\n",
        "        content_clean = self.preprocess_text(content)\n",
        "        return int(util.pytorch_cos_sim(self.similarity_model.encode(query_clean),\n",
        "                                        self.similarity_model.encode(content_clean)).item() * 100)\n",
        "\n",
        "    def check_facts(self, content: str) -> int:\n",
        "        \"\"\"Cross-checks extracted content with Google Fact Check API.\"\"\"\n",
        "        if not content:\n",
        "            return 50\n",
        "        api_url = f\"https://toolbox.google.com/factcheck/api/v1/claimsearch?query={content[:200]}\"\n",
        "        try:\n",
        "            response = requests.get(api_url)\n",
        "            data = response.json()\n",
        "            return 80 if \"claims\" in data and data[\"claims\"] else 40\n",
        "        except:\n",
        "            return 50\n",
        "\n",
        "    def detect_bias(self, content: str) -> int:\n",
        "        \"\"\"Uses NLP sentiment analysis to detect potential bias in content.\"\"\"\n",
        "        if not content:\n",
        "            return 50\n",
        "        sentiment_result = self.sentiment_analyzer(content[:512])[0]\n",
        "        return 100 if sentiment_result[\"label\"] == \"POSITIVE\" else 50 if sentiment_result[\"label\"] == \"NEUTRAL\" else 30\n",
        "\n",
        "    def check_google_scholar(self, url: str) -> int:\n",
        "        \"\"\"Checks Google Scholar citations using SerpAPI.\"\"\"\n",
        "        params = {\"q\": url, \"engine\": \"google_scholar\", \"api_key\": self.serpapi_key}\n",
        "        try:\n",
        "            response = requests.get(\"https://serpapi.com/search\", params=params)\n",
        "            data = response.json()\n",
        "            return min(len(data.get(\"organic_results\", [])) * 10, 100)\n",
        "        except:\n",
        "            return 0\n",
        "    def get_domain_trust_huggingface(self, content: str) -> int:\n",
        "      \"\"\" Uses a Hugging Face fake news detection model to assess credibility with summarized content. \"\"\"\n",
        "      if not content:\n",
        "          return 50\n",
        "      summarized_content = summarize_text(content)\n",
        "      result = self.fake_news_classifier(summarized_content[:512])[0]  # Process only first 512 characters\n",
        "      return 100 if result[\"label\"] == \"REAL\" else 30 if result[\"label\"] == \"FAKE\" else 50\n",
        "\n",
        "\n",
        "    def get_star_rating(self, score: float) -> tuple:\n",
        "        \"\"\"Converts a score (0-100) into a 1-5 star rating.\"\"\"\n",
        "        stars = max(1, min(5, round(score / 20)))\n",
        "        return stars, \"⭐\" * stars\n",
        "\n",
        "    def generate_explanation(self, domain_trust, similarity_score, fact_check_score, bias_score, citation_score) -> str:\n",
        "        \"\"\"Generates a human-readable explanation for the score.\"\"\"\n",
        "        reasons = []\n",
        "        if domain_trust < 50:\n",
        "            reasons.append(\"The source has low domain authority.\")\n",
        "        if similarity_score < 50:\n",
        "            reasons.append(\"The content is not highly relevant to your query.\")\n",
        "        if fact_check_score < 50:\n",
        "            reasons.append(\"Limited fact-checking verification found.\")\n",
        "        if bias_score < 50:\n",
        "            reasons.append(\"Potential bias detected in the content.\")\n",
        "        if citation_score < 30:\n",
        "            reasons.append(\"Few citations found for this content.\")\n",
        "        return \" \".join(reasons) if reasons else \"This source is highly credible and relevant.\"\n",
        "\n",
        "    def rate_url_validity(self, user_query: str, url: str) -> dict:\n",
        "        \"\"\"Main function to evaluate the validity of a webpage.\"\"\"\n",
        "        content = self.fetch_page_content(url)\n",
        "        domain_trust = self.get_domain_trust(content)\n",
        "        similarity_score = self.compute_similarity_score(user_query, content)\n",
        "        fact_check_score = self.check_facts(content)\n",
        "        bias_score = self.detect_bias(content)\n",
        "        citation_score = self.check_google_scholar(url)\n",
        "\n",
        "        final_score = (\n",
        "            (0.3 * domain_trust) +\n",
        "            (0.3 * similarity_score) +\n",
        "            (0.2 * fact_check_score) +\n",
        "            (0.1 * bias_score) +\n",
        "            (0.1 * citation_score)\n",
        "        )\n",
        "\n",
        "        stars, icon = self.get_star_rating(final_score)\n",
        "        explanation = self.generate_explanation(domain_trust, similarity_score, fact_check_score, bias_score, citation_score)\n",
        "\n",
        "        return {\n",
        "            \"raw_score\": {\n",
        "                \"Domain Trust\": domain_trust,\n",
        "                \"Content Relevance\": similarity_score,\n",
        "                \"Fact-Check Score\": fact_check_score,\n",
        "                \"Bias Score\": bias_score,\n",
        "                \"Citation Score\": citation_score,\n",
        "                \"Final Validity Score\": final_score\n",
        "            },\n",
        "            \"stars\": {\n",
        "                \"score\": stars,\n",
        "                \"icon\": icon\n",
        "            },\n",
        "            \"explanation\": explanation\n",
        "        }\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMqlKDcDPT_T",
        "outputId": "26400f22-522a-46db-a851-e60fb1472655"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Instantiate the URLValidator class\n",
        "validator = URLValidator()\n",
        "\n",
        "# Define user prompt and URL\n",
        "user_prompt = \"I have just been on an international flight, can I come back home to hold my 1-month-old newborn?\"\n",
        "url_to_check = \"https://www.mayoclinic.org/healthy-lifestyle/infant-and-toddler-health/expert-answers/air-travel-with-infant/faq-20058539\"\n",
        "\n",
        "# Run the validation\n",
        "result = validator.rate_url_validity(user_prompt, url_to_check)\n",
        "\n",
        "# Print the results\n",
        "import json\n",
        "print(json.dumps(result, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFK3CyYuRbgi",
        "outputId": "429f6f72-ece9-474a-8205-2a881fb2e8b1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"raw_score\": {\n",
            "    \"Domain Trust\": 50,\n",
            "    \"Content Relevance\": 46,\n",
            "    \"Fact-Check Score\": 50,\n",
            "    \"Bias Score\": 30,\n",
            "    \"Citation Score\": 0,\n",
            "    \"Final Validity Score\": 41.8\n",
            "  },\n",
            "  \"stars\": {\n",
            "    \"score\": 2,\n",
            "    \"icon\": \"\\u2b50\\u2b50\"\n",
            "  },\n",
            "  \"explanation\": \"The content is not highly relevant to your query. Potential bias detected in the content. Few citations found for this content.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "# Instantiate the URLValidator class\n",
        "validator = URLValidator()\n",
        "\n",
        "# Define user prompt and URL\n",
        "user_prompt = \"I have just been on an international flight, can I come back home to hold my 1-month-old newborn?\"\n",
        "url_to_check = \"https://www.mayoclinic.org/healthy-lifestyle/infant-and-toddler-health/expert-answers/air-travel-with-infant/faq-20058539\"\n",
        "\n",
        "# Run the validation\n",
        "result = validator.rate_url_validity(user_prompt, url_to_check)\n",
        "\n",
        "# Define the CSV file path\n",
        "csv_file_path = 'url_validation_results.csv'\n",
        "\n",
        "# Check if the file exists (for appending or creating)\n",
        "file_exists = os.path.isfile(csv_file_path)\n",
        "\n",
        "# Open the CSV file in append mode\n",
        "with open(csv_file_path, mode='a', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # If the file doesn't exist, write the header\n",
        "    if not file_exists:\n",
        "        writer.writerow([\n",
        "            \"User Prompt\", \"URL\", \"Star Rating\", \"Final Validity Score\"\n",
        "        ])\n",
        "\n",
        "    # Write the current data row\n",
        "    writer.writerow([\n",
        "        user_prompt,  # User prompt\n",
        "        url_to_check,  # URL to check\n",
        "        result['stars']['score'],  # Star rating\n",
        "        result['raw_score']['Final Validity Score']  # Final validity score\n",
        "    ])\n",
        "\n",
        "print(f\"CSV file saved at {csv_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjVMJWOQU3n_",
        "outputId": "cda28d85-be76-4fbe-d213-faa7864b9ea8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file saved at url_validation_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "# Instantiate the URLValidator class\n",
        "validator = URLValidator()\n",
        "\n",
        "# Define user prompt and URL\n",
        "user_prompt = \"what is AI\"\n",
        "url_to_check = \"https://cloud.google.com/learn/what-is-artificial-intelligence\"\n",
        "# Run the validation\n",
        "result = validator.rate_url_validity(user_prompt, url_to_check)\n",
        "print(result)\n",
        "# Define the CSV file path\n",
        "csv_file_path = 'url_validation_results.csv'\n",
        "\n",
        "# Check if the file exists (for appending or creating)\n",
        "file_exists = os.path.isfile(csv_file_path)\n",
        "\n",
        "# Open the CSV file in append mode\n",
        "with open(csv_file_path, mode='a', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # If the file doesn't exist, write the header\n",
        "    if not file_exists:\n",
        "        writer.writerow([\n",
        "            \"User Prompt\", \"URL\", \"Star Rating\", \"Final Validity Score\"\n",
        "        ])\n",
        "\n",
        "    # Write the current data row\n",
        "    writer.writerow([\n",
        "        user_prompt,  # User prompt\n",
        "        url_to_check,  # URL to check\n",
        "        result['stars']['score'],  # Star rating\n",
        "        result['raw_score']['Final Validity Score']  # Final validity score\n",
        "    ])\n",
        "\n",
        "print(f\"CSV file saved at {csv_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCp1lUhuXSGv",
        "outputId": "877db475-c86f-4020-eb7e-60b2eff2f396"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'raw_score': {'Domain Trust': 50, 'Content Relevance': 54, 'Fact-Check Score': 50, 'Bias Score': 30, 'Citation Score': 0, 'Final Validity Score': 44.2}, 'stars': {'score': 2, 'icon': '⭐⭐'}, 'explanation': 'Potential bias detected in the content. Few citations found for this content.'}\n",
            "CSV file saved at url_validation_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the CSV file and read its contents\n",
        "with open(csv_file_path, mode='r', newline='', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "\n",
        "    # Iterate over the rows in the CSV file and print them\n",
        "    for row in reader:\n",
        "        print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKw2m1QAXqlR",
        "outputId": "c1ca620c-1548-4fda-8d6d-63c0e08f2f2f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['User Prompt', 'URL', 'Star Rating', 'Final Validity Score']\n",
            "['I have just been on an international flight, can I come back home to hold my 1-month-old newborn?', 'https://www.mayoclinic.org/healthy-lifestyle/infant-and-toddler-health/expert-answers/air-travel-with-infant/faq-20058539', '2', '42.2']\n",
            "['What are the benefits of a vegetarian diet?', 'https://www.nhs.uk/live-well/eat-well/how-to-eat-a-balanced-diet/the-vegetarian-diet/', '2', '40.0']\n",
            "['What are the benefits of a vegetarian diet?', 'https://www.nhs.uk/live-well/eat-well/how-to-eat-a-balanced-diet/the-vegetarian-diet/', '2', '40.0']\n",
            "['What are the benefits of a vegetarian diet?', 'https://pubmed.ncbi.nlm.nih.gov/37226630/#:~:text=Plant%2Dbased%20diets%20have%20the,the%20risk%20of%20cardiovascular%20disease.', '2', '43.8']\n",
            "['How to improve mental health during stressful times?', 'https://www.who.int/news-room/questions-and-answers/item/stress#:~:text=Stress%20is%20a%20natural%20human,experiences%20stress%20to%20some%20degree.', '3', '51.8']\n",
            "['How to improve mental health during stressful times?', \"https://www.hcf.com.au/health-agenda/body-mind/mental-health/downsides-to-always-being-positive#:~:text=A%20study%20from%20the%20University,we're%20making%20them%20stronger.\", '2', '42.4']\n",
            "['How to improve mental health during stressful times?', 'https://www.mentalhealth.org.uk/explore-mental-health/a-z-topics/diet-and-mental-health#:~:text=Other%20ways%20I%20can%20take,of%20well%2Dbeing%20and%20mood.', '2', '41.0']\n",
            "['How to improve mental health during stressful times?', 'https://www.mentalhealth.org.uk/explore-mental-health/a-z-topics/diet-and-mental-health#:~:text=Other%20ways%20I%20can%20take,of%20well%2Dbeing%20and%20mood.', '2', '40.0']\n",
            "['What are the dangers of smoking?', 'https://hikingoing.com/wp-content/uploads/2022/07/Eat-Move-Make-Food-Fitness-Travel-Lifestyle07.jpg', '2', '30.0']\n",
            "['What are the dangers of smoking?', 'https://www.health.gov.au/topics/smoking-vaping-and-tobacco/about-smoking/effects#:~:text=Smoking%20is%20major%20cause%20of,of%20death%20for%20both%20men', '2', '30.0']\n",
            "['What are the dangers of smoking?', 'https://www.cdc.gov/tobacco/campaign/tips/diseases/secondhand-smoke-asthma.html#:~:text=Tobacco%20smoke%20is%20a%20common,everyone%2C%20especially%20people%20with%20asthma.', '2', '40.6']\n",
            "['How does exercise impact your health?', 'https://www.betterhealth.vic.gov.au/health/healthyliving/physical-activity-its-important', '2', '45.7']\n",
            "['what is AI', 'https://cloud.google.com/learn/what-is-artificial-intelligence', '2', '44.2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBtLdWTTXvF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}